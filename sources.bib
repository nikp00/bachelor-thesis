@inproceedings{evaluation_of_visual_tracking_algorithms_for_embedded_devices,
  author    = {Lehtola, Ville
               and Huttunen, Heikki
               and Christophe, Francois
               and Mikkonen, Tommi},
  editor    = {Sharma, Puneet
               and Bianchi, Filippo Maria},
  title     = {Evaluation of Visual Tracking Algorithms for Embedded Devices},
  booktitle = {Image Analysis},
  year      = {2017},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {88--97},
  abstract  = {Today's embedded platforms enable executing difficult tasks such as visual tracking. However, such resource-constrained systems are still facing challenges regarding the performance and accuracy in executing these tasks. This paper presents the evaluation of 5 open-source visual tracking implementations available from the contributions branch of the Open Computer Vision (OpenCV) library. This evaluation is performed based on the performance and accuracy of these implementations when embedded in a Raspberry Pi. The algorithms evaluated are On-Line Boosting, Multiple Instance Learning (MIL), Median Flow, Tracking-Learning-Detection (TLD), and Kernelized Correlation Filters (KCF). Even if commercial implementations of these algorithms perform better than their open-source version, the popularity of OpenCV motivates this evaluation. Tests are based on a benchmark of 100 video streams from which the tracking implementations should follow moving objects. The algorithms are evaluated for accuracy using averaged Jaccard indices and for performance by measuring their frame rate. We want to find an open-source implementation that performs well on these two criteria when tested on an embedded platform. Results show Median Flow being the fastest but its accuracy is the lowest. We therefore recommend KCF as it is the second fastest and the most accurate.},
  isbn      = {978-3-319-59126-1}
}

@inproceedings{attention_is_all_you_need,
  title  = {Attention is All You Need},
  author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year   = {2017},
  url    = {https://arxiv.org/pdf/1706.03762.pdf}
}

@inproceedings{stark,
  title     = {Learning spatio-temporal transformer for visual tracking},
  author    = {Yan, Bin and Peng, Houwen and Fu, Jianlong and Wang, Dong and Lu, Huchuan},
  booktitle = {Proceedings of the IEEE/CVF international conference on computer vision},
  pages     = {10448--10457},
  year      = {2021}
}

@inproceedings{resnet,
  title     = {Deep residual learning for image recognition},
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {770--778},
  year      = {2016}
}



@article{real_time_multiple_object_visual_tracking_for_embedded_gpu_systems,
  author  = {Fernández-Sanjurjo, Mauro and Mucientes, Manuel and Brea, Víctor Manuel},
  journal = {IEEE Internet of Things Journal},
  title   = {Real-Time Multiple Object Visual Tracking for Embedded GPU Systems},
  year    = {2021},
  volume  = {8},
  number  = {11},
  pages   = {9177-9188},
  doi     = {10.1109/JIOT.2021.3056239}
}

@online{nn_vs_dnn,
  title   = {What Is Deep Learning?},
  author  = {Nisarg Patel},
  url     = {https://medium.com/@nnpatel4583/what-is-deep-learning-4daa22ceea4e},
  urldate = {2023}
}

@online{cnn,
  title   = {Binary Image classifier CNN using TensorFlow},
  author  = {Sai Balaji},
  url     = {https://medium.com/techiepedia/binary-image-classifier-cnn-using-tensorflow-a3f5d6746697},
  urldate = {2023}
}

